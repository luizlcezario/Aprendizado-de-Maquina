---
title: "Solução Lista 02"
author: |
        | Nome: Paulo Augusto D. Araújo
        | E-mail: augusto.dantas@aluno.ufabc.edu.br
        | Nome: Luiz Lima Cezario
        | E-mail: luiz.cezario@aluno.ufabc.edu.br
        | (Não é preciso informar os RAs)
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE, echo= FALSE}
knitr::opts_chunk$set(echo = T,
                      fig.align='center',
                      cache=TRUE,
                      out.width = "60%",
                      out.heigth = "60%",
                      warning=FALSE,
                      message=FALSE)
options(width =70)
```

## Exercício 01

```{r echo=FALSE}

library(tidymodels)
## Cria o modelo knn

train <- tibble(x = runif(50, -1, 1),
                  e = rnorm(50,0, 0.5),
                  y = x^2-2*x^3+1+e)
test <- tibble(x = runif(100, -1, 1),
                  e = rnorm(100,0, 0.5),
                  y = x^2-2*x^3+1+e)

knn.model <- nearest_neighbor(neighbors = 10,
              weight_func = "rectangular",
              dist_power = 2) %>%
          set_engine("kknn") %>%
          set_mode("regression")

## Faz o treinamento
knn.fit <- knn.model %>%
        fit( y ~ x, data = train)


## Faz a predição
test.pred <- knn.fit %>%
          predict( new_data = test) %>%
          bind_cols( test ) ## Adiciona as predicoes como coluna
## da tabela test



## Calcula o erro
error = rmse(test.pred, y, .pred)
cat('o erro para k = 10 foi', error$.estimate)

knn.model <- nearest_neighbor(neighbors = 1,
              weight_func = "rectangular",
              dist_power = 2) %>%
          set_engine("kknn") %>%
          set_mode("regression")

## Faz o treinamento
knn.fit <- knn.model %>%
        fit( y ~ x, data = train)


## Faz a predição
test.pred <- knn.fit %>%
          predict( new_data = test) %>%
          bind_cols( test ) ## Adiciona as predicoes como coluna
## da tabela test



## Calcula o erro
error = rmse(test.pred, y, .pred)

cat('o erro para k = 1 foi', error$.estimate)


## Cria o modelo linear
lin.model <- linear_reg() %>%
          set_engine("lm") %>%
          set_mode("regression")

## Faz o treinamento
lin.fit <- lin.model %>%
            fit( y ~ x, data = train)


test.pred <- lin.fit %>%
          predict( new_data = test) %>%
          bind_cols( test )

error = rmse(test.pred, y, .pred)

cat('o erro para a regressao linear foi', error$.estimate)


```

## Exercício 02
```{r echo=FALSE}
library(tidyverse)
library(mlbench)
library(GGally)
data("PimaIndiansDiabetes")
pima_indians <- as_tibble(PimaIndiansDiabetes)
ggpairs(pima_indians, colums = 2:8)
```
###Escolhendo as colunas 2 e 8 plotamos o gráfico de pares
###relacionando nível de glucose e idade


## Exercício 03

```{r echo=FALSE}
library(tidymodels)
tt.split <- initial_split(pima_indians,prop = 0.8)
# Train/test serão nossos conjunto de treinamento e testes
train <- training(tt.split)
test <- testing(tt.split)
errors <- tibble(k = 1:50,
                error = 1:50)

for(i in 1:50)
{
  
knn.model <- nearest_neighbor(neighbors = i,
              weight_func = "rectangular",
              dist_power = 2) %>%
          set_engine("kknn") %>%
          set_mode('classification')

## Faz o treinamento
knn.fit <- knn.model %>%
        fit(diabetes ~ ., data = train)


## Faz a predição
test.pred <- knn.fit %>%
          predict( new_data = test) %>%
          bind_cols( test ) ## Adiciona as predicoes como coluna
## da tabela test

## Calcula o erro

error <- accuracy(test.pred, diabetes, .pred_class)

errors$error[i] =  error$.estimate
}
test <- errors %>% arrange(error)
cat("de acordo com os test o melhor vasco da gama e o k = ",test$k[1])

```
## Exercício 04

```{r echo=FALSE}
cv.split <- vfold_cv(pima_indians,v=10)
errors <- tibble(k = 1:10,
                error = 1:10,
                stderr = 1:10)
## Montamos o nosso modelo de kNN
for(i in 1:10)
{
  knn.model <- nearest_neighbor(neighbors = i + i, # $k$ = número de vizinhos
              weight_func = "rectangular", # ponderação retangular
              dist_power = 2) %>% # distância Euclideana
              set_engine("kknn") %>%
              set_mode("classification")
              # Calculando a acurraria usando os conjuntos de
              # validação cruzada. A função fit_resamples faz
              # o trabalho sujo para você aqui.
  knn.fits <- fit_resamples(knn.model, # Modelo
            diabetes ~ ., # Fórmula (predizer diabetes com todos preditores)
            resamples = cv.split) # Folds
            # Você pode coletar a acurácia chamando a função collect_metrics
  
  dados <- knn.fits %>% collect_metrics()

  errors$error[i] = dados[1,3]$mean;

}
ggplot(errors, aes("1/k", "mean")) + geom_point(aes(1 /k + k, error ))


```